---
title: "Code"
author: "Emily Mittleman & Julia Rosner"
date: '2022-12-05'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(broom)
library(stringr)
library(knitr)
library(nnet)
library(ggplot2)
library(MASS)
library(ISLR)
library(leaps)
library(glmnet)
library(mgcv)
library(car)
library(splines)
library(ggpubr)
library(corrplot)
```


This file will be used for our initial code while we explore the data, different models, etc. Then we'll compile it into Report.Rmd

### Load Data
```{r load data}
data <- read.csv("Data/diabetes_012.csv", header = TRUE)
```


### EDA
```{r}
head(data)
```
Look at correlations between variables. helps to know which attributes are highy dependent on the prediction variable
```{r correlations}
correlations <- cor(data)
correlations
corrplot(correlations, method="color")
```

Next, look at box plots of the 2 most correlated predictors and color by outcome.
```{r}
ggplot(data, aes(x = HighBP, fill = factor(Diabetes_012))) +
  geom_bar(position="fill")
```
```{r}
ggplot(data, aes(x = GenHlth, fill = factor(Diabetes_012))) +
  geom_bar(position="fill")
```
```{r}
ggplot(data, aes(x = GenHlth, fill = factor(HighBP))) +
  geom_bar(position="fill")
```
Make pivot table to make historgrams of each variable simpler
```{r}
data_long <- data %>%                          # Apply pivot_longer function
  pivot_longer(colnames(data)) %>% 
  as.data.frame()
head(data_long)
```
Visualize predictor variable distrbutions:

```{r fig.height=10, fig.width=15, fig.fullwidth=TRUE}
ggp1 <- ggplot(data_long, aes(x = value)) +    # Draw each column as histogram
  geom_histogram(bins=10) + 
  facet_wrap(~ name, scales = "free")+ 
  theme(text=element_text(size=20))
ggp1
```

Next, look for outliers in predictors:

```{r make boxplots}
p1 <- ggplot(data, aes(x = BMI, y=factor(Diabetes_012), color=factor(Diabetes_012))) +
  geom_boxplot(outlier.shape=8, outlier.size=4)+
  labs(title="BMI", y="Diabetes")+
  scale_color_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
p2 <- ggplot(data, aes(x = GenHlth, y=factor(Diabetes_012), color=factor(Diabetes_012))) +
  geom_boxplot(outlier.shape=8, outlier.size=4)+
  labs(title="GenHlth",y="Diabetes")+
  scale_color_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
p3 <- ggplot(data, aes(x = MentHlth, y=factor(Diabetes_012), color=factor(Diabetes_012))) +
  geom_boxplot(outlier.shape=8, outlier.size=4)+
  labs(title="MentHlth", y="Diabetes")+
  scale_color_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
p4 <- ggplot(data, aes(x = PhysHlth, y=factor(Diabetes_012), color=factor(Diabetes_012))) +
  geom_boxplot(outlier.shape=8, outlier.size=4)+
  labs(title="PhysHlth",y="Diabetes")+
  scale_color_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
p5 <- ggplot(data, aes(x = Age, y=factor(Diabetes_012), color=factor(Diabetes_012))) +
  geom_boxplot(outlier.shape=8, outlier.size=4)+
  labs(title="Age",y="Diabetes")+
  scale_color_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
p6 <- ggplot(data, aes(x = Education, y=factor(Diabetes_012), color=factor(Diabetes_012))) +
  geom_boxplot(outlier.shape=8, outlier.size=4)+
  labs(title="Education", y="Diabetes")+
  scale_color_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
p7 <- ggplot(data, aes(x = Income, y=factor(Diabetes_012), color=factor(Diabetes_012))) +
  geom_boxplot(outlier.shape=8, outlier.size=4)+
  labs(title="Income", y="Diabetes")+
  scale_color_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
p1
p2
p3
p4
p5
p6
p7
```
From the boxplots above, we see that the predictors BMI, MntHlth, and PhysHlth have a lot of outliers. All three distributions aee very skewed to the right. GenHlth and Age have only a couple outliers. Education and Income have none.

Now, we visulaize predictor distributions and relation to response.
```{r}
ggplot(data, aes(x = GenHlth, fill = factor(Diabetes_012))) +
  geom_bar(position="fill")
ggplot(data, aes(x = GenHlth, fill = factor(Diabetes_012))) +
  geom_bar(position="fill")
```

```{r stacked boxplot per variable}
pbox1 <- ggplot(data, aes(x = HighBP, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="HighBP", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox2 <- ggplot(data, aes(x = HighChol, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="HighChol", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox3 <- ggplot(data, aes(x = CholCheck, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="CholCheck", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox4 <- ggplot(data, aes(x = Smoker, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="Smoker", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox5 <- ggplot(data, aes(x = Stroke, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="Stroke", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox6 <- ggplot(data, aes(x = HeartDiseaseorAttack, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="HeartDiseaseorAttack", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox7 <- ggplot(data, aes(x = PhysActivity, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="PhysActivity", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox8 <- ggplot(data, aes(x = Veggies, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="Veggies", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox9 <- ggplot(data, aes(x = HvyAlcoholConsump, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="HvyAlcoholConsump", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox10 <- ggplot(data, aes(x = AnyHealthcare, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="AnyHealthcare", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox11 <- ggplot(data, aes(x = NoDocbcCost, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="NoDocbcCost", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox12 <- ggplot(data, aes(x = DiffWalk, fill=factor(Diabetes_012))) +
  geom_bar(position="fill")+
  labs(title="DiffWalk", y="Diabetes")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
pbox1
pbox2
pbox3
pbox4
pbox5
pbox6
pbox7
pbox8
pbox9
pbox10
pbox11
pbox12

```

Next, look at "Age" and its relation to response (diabetes diagnosis):

```{r}
ggplot(data, aes(x = Age, fill=factor(Diabetes_012))) +
  geom_bar(position="dodge")+
  labs(title="Age")+
  scale_fill_discrete(name="diabetes", labels=c('no', 'prediabetic', 'yes'))
```


### Factor Numeric Variables

```{r factor data}
factored <- data
```

```{r}
factored$Diabetes_012 <- as.factor(factored$Diabetes_012)
factored$HighBP <- as.factor(factored$HighBP)
factored$CholCheck <- as.factor(factored$CholCheck)
factored$Smoker <- as.factor(factored$Smoker)
factored$Stroke <- as.factor(factored$Stroke)
factored$HeartDiseaseorAttack <- as.factor(factored$HeartDiseaseorAttack)
factored$PhysActivity <- as.factor(factored$PhysActivity)
factored$Fruits <- as.factor(factored$Fruits)
factored$Veggies <- as.factor(factored$Veggies)
factored$HvyAlcoholConsump <- as.factor(factored$HvyAlcoholConsump)
factored$AnyHealthcare <- as.factor(factored$AnyHealthcare)
factored$NoDocbcCost <- as.factor(factored$NoDocbcCost)
factored$GenHlth <- as.factor(factored$GenHlth)
factored$MentHlth <- as.factor(factored$MentHlth)
factored$DiffWalk <- as.factor(factored$DiffWalk)
factored$Sex <- as.factor(factored$Sex)
factored$Age <- as.factor(factored$Age)
factored$Education <- as.factor(factored$Education)
factored$Income <- as.factor(factored$Income)
```

Make diabetes response variable binary
```{r}
factored$diabetes <- ifelse(factored$Diabetes_012 == 0, 0, 1)
factored$diabetes <- as.factor(factored$diabetes)
```

### EDA of factored binary outcome dataset

Next, look at plots of 2 most correlated predictors and color by outcome.
```{r ggplot}
ggplot(factored, aes(x = HighBP, fill = diabetes)) +
  geom_bar(position="fill")
```

```{r}
ggplot(factored, aes(x = GenHlth, fill = diabetes)) +
  geom_bar(position="fill")
```

```{r}
ggplot(factored, aes(x = GenHlth, fill = HighBP)) +
  geom_bar(position="fill")
```

## Modeling

Split data train and test
```{r split data}
set.seed(17)
sample <- sample(c(TRUE, FALSE), nrow(factored), replace=TRUE, prob=c(0.7,0.3))
train  <- factored[sample, ]
test   <- factored[!sample, ]
```


### Logistic Regression

```{r loog reg}
glm.fit.all <- glm(diabetes ~ HighBP+ HighChol + CholCheck + HeartDiseaseorAttack + AnyHealthcare
+ PhysActivity + HvyAlcoholConsump + Fruits + Veggies + GenHlth + DiffWalk + Sex + Income + Education + BMI + PhysHlth, 
               data = factored, family = binomial)
summary(glm.fit.all)
```
```{r}
glm.probs.all <- predict(glm.fit.all, type = "response")
glm.probs.all[1:10]
```


```{r}
glm.pred.all <- rep(0, length(factored$diabetes))
glm.pred.all[glm.probs.all > 0.5] <- 1
```

```{r}
table(glm.pred.all, factored$diabetes)
```

```{r}
accuracy <- sum(diag(table(glm.pred.all, factored$diabetes)))/nrow(factored)
accuracy
```

Now make model based off of training data:

```{r}
glm.fit.trainall <- glm(diabetes ~ HighBP+ HighChol + CholCheck + HeartDiseaseorAttack + AnyHealthcare
+ PhysActivity + HvyAlcoholConsump + Fruits + Veggies + GenHlth + DiffWalk + Sex + Income + Education + BMI + PhysHlth, 
               data = train, family = binomial)
glm.probs.trainall <- predict(glm.fit.trainall, test, type = "response")
```

```{r}
glm.pred.trainall <- rep(0, length(test))
glm.pred.trainall[glm.probs.trainall > 0.5] <- 1
table(glm.pred.trainall, test$diabetes)
```
```{r}
accuracy <- sum(diag(table(glm.pred.trainall, test$diabetes)))/nrow(test)
accuracy
```

To improve the accuracy we will consider a subset of predictors. Look at correlations to decide. The most correlated to diabetes are GenHlth and HighBP.

```{r}
glm.fit.cor <- glm(diabetes ~ GenHlth + HighBP, data=train, family = binomial)
glm.probs.cor <- predict(glm.fit.cor, test, type = "response")
glm.pred.cor <- rep("no diabetes", length(test))
glm.pred.cor[glm.probs.cor > 0.5] <- "diabetes"
table(glm.pred.cor, test$diabetes)
```
```{r}
Accuracy <- (0+5)/(1+18+5+0)
Accuracy
```

The subset of predictors made our predictive performance worse.

### KNN

```{r knn}
#KNN wont knit but works (just takes a while to run)
#library(class)
#set.seed(1)
#knn.pred <- knn(train, test, train$diabetes, k = 10)
#table(knn.pred, test$diabetes)
```

```{r}
#accuracy <- sum(diag(table(knn.pred, test$diabetes)))/nrow(test)
#accuracy
```

Perform CV to find best k value....?

### Trees

```{r}
library(tree)
```

```{r}
tree.all <- tree(diabetes ~ HighBP+ HighChol + CholCheck + HeartDiseaseorAttack + AnyHealthcare
+ PhysActivity + HvyAlcoholConsump + Fruits + Veggies + GenHlth + DiffWalk + Sex + Income + Education + BMI + PhysHlth, factored)
summary(tree.all)
```

```{r}
plot(tree.all)
text(tree.all, pretty = 0)
```
```{r}
set.seed(3)
cv.tree.all <- cv.tree(tree.all, FUN = prune.misclass)
names(cv.tree.all)
```

```{r}
cv.tree.all
```
```{r}
par(mfrow = c(1,2))
plot(cv.tree.all$size, cv.tree.all$dev, type = "b")
plot(cv.tree.all$k, cv.tree.all$dev, type = "b")
```
```{r}
prune.tree <- prune.misclass(tree.all, best = 4)
plot(prune.tree)
text(prune.tree, pretty = 0)
```

